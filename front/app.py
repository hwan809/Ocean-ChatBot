import streamlit as st
from db import GooglesheetUtils
from loc_image import get_location_image
import datetime

__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import sqlite3

from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

from langchain.retrievers.self_query.chroma import ChromaTranslator
from langchain_chroma import Chroma
from langchain.chains.query_constructor.base import AttributeInfo
from langchain.retrievers.self_query.base import SelfQueryRetriever

from langchain.chains.query_constructor.base import (
    StructuredQueryOutputParser,
    get_query_constructor_prompt,
)

openai_api_key = st.secrets['OPENAI_API_KEY']

# Set OpenAI API key
llm = ChatOpenAI(model_name="gpt-4o", temperature=0, openai_api_key=openai_api_key)

# Function to setup RAG pipeline
@st.cache_resource
def setup_rag_pipeline(_retriever):
    prompt = PromptTemplate.from_template(
    """ë‹¹ì‹ ì€ ë¶€ì‚°ê³¼í•™ê³ ë“±í•™êµì˜ í–‰ì‚¬ "Ocean ICT"ì˜ ë„ìš°ë¯¸ ì±—ë´‡ì¸ "í•œë°”ë‹¤" ì…ë‹ˆë‹¤.
    ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•©ë‹ˆë‹¤.
    
    íŒ€ì— ëŒ€í•œ ì •ë³´ë¥¼ ì–¸ê¸‰í•  ë•Œ ë°˜ë“œì‹œ íŒ€ ì½”ë“œë¥¼ ê°™ì´ ì–¸ê¸‰í•˜ì„¸ìš”.
    íŒ€ ì½”ë“œëŠ” ëŒ€ë¬¸ìì™€ ìˆ«ì ë‘ ìë¦¬ì˜ ì¡°í•©ì…ë‹ˆë‹¤.

    ë‹µì„ ëª¨ë¥¸ë‹¤ë©´ ê·¸ëƒ¥ ë‹¹ì‹ ì˜ ì •ë³´ì— ëŒ€í•´ ì–¸ê¸‰í•˜ê³ ,
    Ocean ICTì— ëŒ€í•´ì„œë§Œ ë‹µë³€í•  ìˆ˜ ìˆë‹¤ê³  ë§í•˜ë©´ ë©ë‹ˆë‹¤.
    
    ì ˆëŒ€ë¡œ ìœ íŠœë¸Œ ë§í¬ë¥¼ ì‚¬ìš©ìì—ê²Œ ê³µìœ í•˜ì§€ ë§ê³ , ì•„ë˜ ë™ì˜ìƒì„ ì°¸ì¡°í•´ë‹¬ë¼ê³  í•˜ì„¸ìš”.
    
    ë‹µì„ ì•ˆë‹¤ë©´ ìˆëŠ” ì •ë³´ë¥¼ ì‚¬ìš©í•´ ìµœëŒ€í•œ ìì„¸í•˜ê²Œ ë‹µë³€í•  ìˆ˜ ìˆë„ë¡ í•˜ë˜, ìì‹ ì˜ ì†Œê°œëŠ” í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ì—¬ëŸ¬ ì¤„ì— ê±¸ì³ì„œ ë‹µë³€í•˜ì„¸ìš”.
    í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê³ , ì¹œê·¼í•˜ê²Œ ë‹µí•˜ì‹­ì‹œì˜¤.

    #ì§ˆë¬¸:
    {question}
    #ì •ë³´:
    2023ë…„ì˜ Ocean ICTì—ëŠ” ì´ 86íŒ€ì´ ì°¸ê°€í•˜ì˜€ë‹¤. ë‹¤ìŒì€ ì°¸ê°€í•œ íŒ€ë“¤ì˜ í¬ìŠ¤í„° ì¤‘ ì§ˆë¬¸ê³¼ ê´€ê³„ëœ ì¼ë¶€ì´ë‹¤.
    {context}

    #ë‹µë³€:"""
    )

    chain = prompt | llm | StrOutputParser()

    return chain


# Streamlit UI
st.title("í•œë°”ë‹¤ ğŸ¬")
st.header("2024 Ocean ICT ì±—ë´‡ ë„ìš°ë¯¸")

vectorstore = Chroma(
    persist_directory="db/chroma_2023_pdfs_new",
    embedding_function=OpenAIEmbeddings(openai_api_key=openai_api_key)
)

metadata_field_info = [
    AttributeInfo(
        name="Team code",
        description="Unique code that the team has. alphabetical uppercase + double digit combination.",
        type="string",
    ),
    AttributeInfo(
        name="Title",
        description="the topic that the team studied/made",
        type="string",
    ),
    AttributeInfo(
        name="Teammate #1 name",
        description="A team member's name. name is two or three letters of Hangul.",
        type="string"
    ),

    AttributeInfo(
        name="Teammate #1 number",
        description="A team member's student number. The student number is four digits.",
        type="string"
    ),
    AttributeInfo(
        name="Teammate #2 name",
        description="A team member's name. name is two or three letters of Hangul.",
        type="string"
    ),

    AttributeInfo(
        name="Teammate #2 number",
        description="A team member's student number. The student number is four digits",
        type="string"
    ),

    AttributeInfo(
        name="Youtube link",
        description="A youtube video link from the team. The vido can be played by clicking on the link.",
        type="string"
    )
]

examples = [
    (
        "A23 íŒ€?",
        {
            "query": "ì‘í’ˆ ì„¤ëª…ì„œ",
            "filter": 'eq("Team code", "A23")',
        },
    ),
    (
        "ì´ë™ìœ¤ì€ ë­í–ˆì–´?",
        {
            "query": "ì‘í’ˆ ì„¤ëª…ì„œ",
            "filter": 'or(eq("Teammate #1 name", "ì´ë™ìœ¤"), eq("Teammate #2 name", "ì´ë™ìœ¤"))',
        },
    ),
    (
        "í™˜ê²½ì— ê´€í•œ ì£¼ì œë¡œ ì—°êµ¬í•œ íŒ€ì„ ì•Œë ¤ì¤„ë˜?",
        {
            "query": "í™˜ê²½ì— ê´€í•œ ì£¼ì œë¡œ ì—°êµ¬í•œ íŒ€ì„ ì•Œë ¤ì¤„ë˜?",
            "filter": "NO_FILTER",
        }   
    ),
    (
        "íŒ€ ë²ˆí˜¸ê°€ Bë¡œ ì‹œì‘í•˜ëŠ” í”„ë¡œì íŠ¸ì˜ ì£¼ì œëŠ” ì–´ë–¤ ê²ƒì´ ìˆì–´?",
        {
            "query": "íŒ€ ë²ˆí˜¸ê°€ Bë¡œ ì‹œì‘í•˜ëŠ” í”„ë¡œì íŠ¸ì˜ ì£¼ì œëŠ” ì–´ë–¤ ê²ƒì´ ìˆì–´?",
            "filter": "NO_FILTER",
        }
    ),
    (
        "ë¨¸ì‹ ëŸ¬ë‹ì„ ì‚¬ìš©í•˜ì§€ ì•Šì€ íŒ€ì´ ìˆì„ê¹Œ?",
        {
            "query": "ë¨¸ì‹ ëŸ¬ë‹ì„ ì‚¬ìš©í•˜ì§€ ì•Šì€ íŒ€ì´ ìˆì„ê¹Œ?",
            "filter": "NO_FILTER",
        }
    )
]

# ë¬¸ì„œ ë‚´ìš© ì„¤ëª…ê³¼ ë©”íƒ€ë°ì´í„° í•„ë“œ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ ìƒì„±ê¸° í”„ë¡¬í”„íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
query_prompt = get_query_constructor_prompt(
    'Ocean ICT ëŒ€íšŒì— ì°¸ê°€í•œ íŒ€ì˜ ì‘í’ˆ ì„¤ëª…ì„œ.',
    metadata_field_info,
    examples=examples
)

# êµ¬ì„± ìš”ì†Œì—ì„œ êµ¬ì¡°í™”ëœ ì¿¼ë¦¬ ì¶œë ¥ íŒŒì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
output_parser = StructuredQueryOutputParser.from_components()

# í”„ë¡¬í”„íŠ¸, ì–¸ì–´ ëª¨ë¸, ì¶œë ¥ íŒŒì„œë¥¼ ì—°ê²°í•˜ì—¬ ì¿¼ë¦¬ ìƒì„±ê¸°ë¥¼ ë§Œë“­ë‹ˆë‹¤.
new_query_constructor = query_prompt | llm | output_parser

self_query_retriever = SelfQueryRetriever(
    query_constructor=new_query_constructor,
    vectorstore=vectorstore,
    structured_query_translator=ChromaTranslator()
)

from langchain.retrievers import EnsembleRetriever

# ì•™ìƒë¸” retrieverë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
ensemble_retriever = EnsembleRetriever(
    retrievers=[self_query_retriever, vectorstore.as_retriever()],
    weights=[0.5, 0.5],
    search_type="mmr",
)

# Setup RAG pipeline
qa_chain = setup_rag_pipeline(ensemble_retriever)
googlesheet = GooglesheetUtils()

youtube_link = ''

# from RealtimeTTS import TextToAudioStream, GTTSEngine

# engine = GTTSEngine()
# audio_stream = TextToAudioStream(engine)

# Chat interface
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    if message["role"] == "assistant":
        with st.chat_message(name="assistant", avatar='ğŸ‹'):
            st.markdown(message["content"])
    elif message["role"] == "video":
        with st.chat_message(name="assistant", avatar='ğŸ‹'):
            st.video(message["content"])    
    elif message["role"] == "image":
        with st.chat_message(name="assistant", avatar='ğŸ‹'):
            st.image(message["content"])    
    else:
        with st.chat_message(name="user"):
            st.markdown(message["content"])        

if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message(name="assistant", avatar='ğŸ‹'):
        docs = ensemble_retriever.invoke(prompt)

        stream = qa_chain.stream(
            {
                "context": docs,
                "question": prompt
            }
        )
        response = st.write_stream(stream)
    
    youtube_link = docs[0].metadata['Youtube link']
    team_code = docs[0].metadata['Team code']
    st.session_state.messages.append({"role": "assistant", "content": response})

    now = datetime.datetime.now()
    timestamp = now.strftime("%Y-%m-%d %H:%M:%S")

    values = [[prompt, response, timestamp]]
    googlesheet.append_data(values, 'Sheet1!A1')

    play_video = lambda: st.session_state.messages.append({"role": "video", "content": youtube_link})
    st.button('íŒ€ ì˜ìƒ ë³´ê¸°', on_click=play_video)

    show_loc_img = lambda: st.session_state.messages.append({"role": "image", "content": get_location_image(team_code)})
    st.button('íŒ€ ìœ„ì¹˜ ë³´ê¸°', on_click=show_loc_img)