import streamlit as st
from db import GooglesheetUtils
from loc_image import get_location_image
from datetime import datetime, timedelta

__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import sqlite3

from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

from langchain.retrievers.self_query.chroma import ChromaTranslator
from langchain_chroma import Chroma
from langchain.chains.query_constructor.base import AttributeInfo
from langchain.retrievers.self_query.base import SelfQueryRetriever

from langchain.chains.query_constructor.base import (
    StructuredQueryOutputParser,
    get_query_constructor_prompt,
)

openai_api_key = st.secrets['OPENAI_API_KEY']

# Set OpenAI API key
llm = ChatOpenAI(model_name="gpt-4o", temperature=0, openai_api_key=openai_api_key)

# Function to setup RAG pipeline
@st.cache_resource
def setup_rag_pipeline(_retriever):
    prompt = PromptTemplate.from_template(
    """ë‹¹ì‹ ì€ ë¶€ì‚°ê³¼í•™ê³ ë“±í•™êµì˜ í–‰ì‚¬ "Ocean ICT"ì˜ ë„ìš°ë¯¸ ì±—ë´‡ì¸ "í•œë°”ë‹¤" ì…ë‹ˆë‹¤.
    ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•©ë‹ˆë‹¤.
    íŒ€ì— ëŒ€í•œ ì •ë³´ë¥¼ ì–¸ê¸‰í•  ë•Œ ë°˜ë“œì‹œ íŒ€ ì½”ë“œë¥¼ ê°™ì´ ì–¸ê¸‰í•˜ì„¸ìš”.
    ë‹µì„ ëª¨ë¥¸ë‹¤ë©´ ê·¸ëƒ¥ ë‹¹ì‹ ì˜ ì •ë³´ì— ëŒ€í•´ ì–¸ê¸‰í•˜ê³ , Ocean ICTì— ëŒ€í•´ì„œë§Œ ë‹µë³€í•  ìˆ˜ ìˆë‹¤ê³  ë§í•˜ë©´ ë©ë‹ˆë‹¤.
    ì ˆëŒ€ë¡œ ìœ íŠœë¸Œ ë§í¬ë¥¼ ì‚¬ìš©ìì—ê²Œ ê³µìœ í•˜ì§€ ë§ê³ , ì•„ë˜ ë™ì˜ìƒì„ ì°¸ì¡°í•´ë‹¬ë¼ê³  í•˜ì„¸ìš”.

    Ocean ICTëŠ” ~~ 
    
    ë‹µì„ ì•ˆë‹¤ë©´ 1. ìˆëŠ” ì •ë³´ë¥¼ ì‚¬ìš©í•œ ë‹µê³¼, 2. ë‹µì„ ë„ì¶œí•˜ëŠ” ë° ì§ì ‘ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ë¬¸ì„œì˜ íŒ€ ì½”ë“œ ëª©ë¡ì„ ë¬¸ì '|'ë¡œ êµ¬ë¶„í•´ ì•ˆë‚´í•©ë‹ˆë‹¤. 
    ì—†ìœ¼ë©´ Noneìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤. í•˜ë‚˜ ì´ìƒì˜ ì¶œì²˜ê°€ ìˆëŠ” ê²½ìš° ë§¨ ë’¤ì— í•œêº¼ë²ˆì— í‘œì‹œí•˜ì„¸ìš”. 
    ë‹µë³€ì˜ ëì—ëŠ” '|'ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    ì˜ˆì‹œ ë‹µë³€: B03 íŒ€ê³¼ A11 íŒ€ì´ ìˆìŠµë‹ˆë‹¤. | B03 | A11

    #ì§ˆë¬¸:
    {question}
    #ì •ë³´:
    2023ë…„ì˜ Ocean ICTì—ëŠ” ì´ 86íŒ€ì´ ì°¸ê°€í•˜ì˜€ë‹¤. ë‹¤ìŒì€ ì°¸ê°€í•œ íŒ€ë“¤ì˜ í¬ìŠ¤í„° ì¤‘ ì§ˆë¬¸ê³¼ ê´€ê³„ëœ ì¼ë¶€ì´ë‹¤.
    {context}

    #ë‹µë³€:"""
    )
    
    #ì˜ˆì‹œ) {'answer': 'B03 íŒ€ì€..', 'source': 'B03'}

    chain = prompt | llm | StrOutputParser()

    return chain

def find_document(docs, team_code):
    for doc in docs:
        if doc.metadata['Team code'] == team_code:
            return doc
    return None

# Streamlit UI
st.title("í•œë°”ë‹¤ ğŸ¬")
st.header("2024 Ocean ICT ì±—ë´‡ ë„ìš°ë¯¸")

vectorstore = Chroma(
    persist_directory="db/chroma_2024_pdfs",
    embedding_function=OpenAIEmbeddings(openai_api_key=openai_api_key)
)

metadata_field_info = [
    AttributeInfo(
        name="Team code",
        description="Unique code that the team has. alphabetical uppercase + double digit combination.",
        type="string",
    ),
    AttributeInfo(
        name="Title",
        description="the topic that the team studied/made",
        type="string",
    ),
    AttributeInfo(
        name="Teammate #1 name",
        description="A team member's name. name is two or three letters of Hangul.",
        type="string"
    ),

    AttributeInfo(
        name="Teammate #1 number",
        description="A team member's student number. The student number is four digits.",
        type="string"
    ),
    AttributeInfo(
        name="Teammate #2 name",
        description="A team member's name. name is two or three letters of Hangul.",
        type="string"
    ),

    AttributeInfo(
        name="Teammate #2 number",
        description="A team member's student number. The student number is four digits",
        type="string"
    ),

    AttributeInfo(
        name="Youtube link",
        description="A youtube video link from the team. The vido can be played by clicking on the link.",
        type="string"
    )
]

examples = [
    (
        "A23 íŒ€?",
        {
            "query": "ì‘í’ˆ ì„¤ëª…ì„œ",
            "filter": 'eq("Team code", "A23")',
        },
    ),
    (
        "ì´ë™ìœ¤ì€ ë­í–ˆì–´?",
        {
            "query": "ì‘í’ˆ ì„¤ëª…ì„œ",
            "filter": 'or(eq("Teammate #1 name", "ì´ë™ìœ¤"), eq("Teammate #2 name", "ì´ë™ìœ¤"))',
        },
    ),
    (
        "í™˜ê²½ì— ê´€í•œ ì£¼ì œë¡œ ì—°êµ¬í•œ íŒ€ì„ ì•Œë ¤ì¤„ë˜?",
        {
            "query": "í™˜ê²½ì— ê´€í•œ ì£¼ì œë¡œ ì—°êµ¬í•œ íŒ€ì„ ì•Œë ¤ì¤„ë˜?",
            "filter": "NO_FILTER",
        }   
    ),
    (
        "íŒ€ ë²ˆí˜¸ê°€ Bë¡œ ì‹œì‘í•˜ëŠ” í”„ë¡œì íŠ¸ì˜ ì£¼ì œëŠ” ì–´ë–¤ ê²ƒì´ ìˆì–´?",
        {
            "query": "íŒ€ ë²ˆí˜¸ê°€ Bë¡œ ì‹œì‘í•˜ëŠ” í”„ë¡œì íŠ¸ì˜ ì£¼ì œëŠ” ì–´ë–¤ ê²ƒì´ ìˆì–´?",
            "filter": "NO_FILTER",
        }
    ),
    (
        "ë¨¸ì‹ ëŸ¬ë‹ì„ ì‚¬ìš©í•˜ì§€ ì•Šì€ íŒ€ì´ ìˆì„ê¹Œ?",
        {
            "query": "ë¨¸ì‹ ëŸ¬ë‹ì„ ì‚¬ìš©í•˜ì§€ ì•Šì€ íŒ€ì´ ìˆì„ê¹Œ?",
            "filter": "NO_FILTER",
        }
    )
]

# ë¬¸ì„œ ë‚´ìš© ì„¤ëª…ê³¼ ë©”íƒ€ë°ì´í„° í•„ë“œ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ ìƒì„±ê¸° í”„ë¡¬í”„íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
query_prompt = get_query_constructor_prompt(
    'Ocean ICT ëŒ€íšŒì— ì°¸ê°€í•œ íŒ€ì˜ ì‘í’ˆ ì„¤ëª…ì„œ.',
    metadata_field_info,
    examples=examples
)

# êµ¬ì„± ìš”ì†Œì—ì„œ êµ¬ì¡°í™”ëœ ì¿¼ë¦¬ ì¶œë ¥ íŒŒì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
output_parser = StructuredQueryOutputParser.from_components()

# í”„ë¡¬í”„íŠ¸, ì–¸ì–´ ëª¨ë¸, ì¶œë ¥ íŒŒì„œë¥¼ ì—°ê²°í•˜ì—¬ ì¿¼ë¦¬ ìƒì„±ê¸°ë¥¼ ë§Œë“­ë‹ˆë‹¤.
new_query_constructor = query_prompt | llm | output_parser

self_query_retriever = SelfQueryRetriever(
    query_constructor=new_query_constructor,
    vectorstore=vectorstore,
    structured_query_translator=ChromaTranslator()
)

from langchain.retrievers import EnsembleRetriever

# ì•™ìƒë¸” retrieverë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
ensemble_retriever = EnsembleRetriever(
    retrievers=[self_query_retriever, vectorstore.as_retriever()],
    weights=[0.5, 0.5],
    search_type="mmr",
)

# Setup RAG pipeline
qa_chain = setup_rag_pipeline(ensemble_retriever)
googlesheet = GooglesheetUtils()

used_doc_vid = ''

# Chat interface
if "messages" not in st.session_state:
    st.session_state.messages = []

for i in range(len(st.session_state.messages)):
    message = st.session_state.messages[i]
    if message["role"] == "assistant":
        with st.chat_message(name="assistant", avatar='ğŸ‹'):
            st.markdown(message["content"])
    elif message["role"] == "video":
        with st.chat_message(name="assistant", avatar='ğŸ‹'):
            st.video(message["content"])    
    elif message["role"] == "image":
        with st.chat_message(name="assistant", avatar='ğŸ‹'):
            st.image(message["content"], width=360)    
    else:
        with st.chat_message(name="user"):
            st.markdown(message["content"])
        

if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message(name="assistant", avatar='ğŸ‹'):
        docs = ensemble_retriever.invoke(prompt)
        stream = qa_chain.stream(
            {
                "context": docs,
                "question": prompt
            }
        )
        response = st.write_stream(stream)

    used_team_code = [i.strip() for i in response.split('|')[1:]]

    if len(used_team_code) == 1 and 'None' not in used_team_code:
        used_doc = find_document(docs, used_team_code[0])
        used_doc_vid = used_doc.metadata['Youtube link']

        play_video = lambda: st.session_state.messages.append({"role": "video", "content": used_doc_vid})
        show_loc_img = lambda: st.session_state.messages.append({"role": "image", "content": get_location_image(used_team_code)})
        
        col1, col2, col3 = st.columns([1, 1, 3])

        with col1:
            st.button('íŒ€ ì˜ìƒ ë³´ê¸°', on_click=play_video)
        with col2:
            st.button('íŒ€ ìœ„ì¹˜ ë³´ê¸°', on_click=show_loc_img)

    st.session_state.messages.append({"role": "assistant", "content": response})        
    now = datetime.now() + timedelta(hours=9)
    timestamp = now.strftime("%Y-%m-%d %H:%M:%S")

    values = [[prompt, response, timestamp]]
    googlesheet.append_data(values, 'Sheet1!A1')