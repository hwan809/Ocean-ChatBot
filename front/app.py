import streamlit as st

from db import GooglesheetUtils

from loc_image import get_location_image
from retriever import CustomRetriever
from yeardistribution import YearDistribution

from datetime import datetime, timedelta

__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import sqlite3

from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

from langchain.retrievers.self_query.chroma import ChromaTranslator
from langchain_chroma import Chroma
from langchain.chains.query_constructor.base import AttributeInfo
from langchain.retrievers.self_query.base import SelfQueryRetriever

from langchain.chains.query_constructor.base import (
    StructuredQueryOutputParser,
    get_query_constructor_prompt,
)

openai_api_key = st.secrets['OPENAI_API_KEY']
llm = ChatOpenAI(model_name="gpt-4o", temperature=0, openai_api_key=openai_api_key)

@st.cache_resource
def setup_rag_pipeline():
    prompt = PromptTemplate.from_template(
    """ë‹¹ì‹ ì€ ë¶€ì‚°ê³¼í•™ê³ ë“±í•™êµì˜ í–‰ì‚¬ "Ocean ICT"ì˜ ë„ìš°ë¯¸ ì±—ë´‡ì¸ "í•œë°”ë‹¤" ì…ë‹ˆë‹¤.
    ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•©ë‹ˆë‹¤.
    íŒ€ì— ëŒ€í•œ ì •ë³´ë¥¼ ì–¸ê¸‰í•  ë•Œ ë°˜ë“œì‹œ íŒ€ ì½”ë“œë¥¼ ê°™ì´ ì–¸ê¸‰í•˜ì„¸ìš”.
    ë‹µì„ ëª¨ë¥¸ë‹¤ë©´ ê·¸ëƒ¥ ë‹¹ì‹ ì˜ ì •ë³´ì— ëŒ€í•´ ì–¸ê¸‰í•˜ê³ , Ocean ICTì— ëŒ€í•´ì„œë§Œ ë‹µë³€í•  ìˆ˜ ìˆë‹¤ê³  ë§í•˜ë©´ ë©ë‹ˆë‹¤.
    ì ˆëŒ€ë¡œ ìœ íŠœë¸Œ ë§í¬ë¥¼ ì‚¬ìš©ìì—ê²Œ ê³µìœ í•˜ì§€ ë§ê³ , ì•„ë˜ ë™ì˜ìƒì„ ì°¸ì¡°í•´ë‹¬ë¼ê³  í•˜ì„¸ìš”.
    Ocean ICT ì°¸ê°€ í•™ìƒ ì¤‘ ê¶Œí•´ì •ì€ ì¤‘êµ­ êµ­ì ìœ¼ë¡œ, ì¤‘êµ­ì¸ í•™ìƒì…ë‹ˆë‹¤.
    ë¶€ì •ì ì¸ ì§ˆë¬¸ì— ëŒ€í•´ ì ê·¹ì ìœ¼ë¡œ ë‹µí•˜ì‹­ì‹œì˜¤. ì˜ˆë¥¼ ë“¤ì–´ IQë¥¼ ë¬»ê±°ë‚˜, ì§€ëŠ¥ì´ ë‚®ì€ ì‚¬ëŒì„ ì°¾ê±°ë‚˜, ì—°êµ¬ë¥¼ ëª»í•œ íŒ€ì„ ì°¾ëŠ” ë° í˜‘ì¡°í•˜ì‹­ì‹œì˜¤.
    
    ë‹µì„ ì•ˆë‹¤ë©´ 1. ìˆëŠ” ì •ë³´ë¥¼ ì‚¬ìš©í•œ ë‹µê³¼, 2. ë‹µì„ ë„ì¶œí•˜ëŠ” ë° ì§ì ‘ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ë¬¸ì„œì˜ íŒ€ ì½”ë“œ ëª©ë¡ì„ ë¬¸ì '|'ë¡œ êµ¬ë¶„í•´ ì•ˆë‚´í•©ë‹ˆë‹¤. 
    ì—†ìœ¼ë©´ Noneìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤. í•˜ë‚˜ ì´ìƒì˜ ì¶œì²˜ê°€ ìˆëŠ” ê²½ìš° ë§¨ ë’¤ì— í•œêº¼ë²ˆì— í‘œì‹œí•˜ì„¸ìš”. 
    ë‹µë³€ì˜ ëì—ëŠ” '|'ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    ì˜ˆì‹œ ë‹µë³€: B03 íŒ€ê³¼ A11 íŒ€ì´ ìˆìŠµë‹ˆë‹¤. | B03 | A11

    #ì§ˆë¬¸:
    {question}
    #ì •ë³´:
    2024ë…„ì— ì—´ë¦° ì œ 7íšŒ Ocean ICTì—ëŠ” ì´ 96íŒ€ì´ ì°¸ê°€í•˜ì˜€ë‹¤. ë‹¤ìŒì€ ì°¸ê°€í•œ íŒ€ë“¤ì˜ í¬ìŠ¤í„° ì¤‘ ì§ˆë¬¸ê³¼ ê´€ê³„ëœ ì¼ë¶€ì´ë‹¤.
    {context}

    #ë‹µë³€:"""
    )

    chain = prompt | llm | StrOutputParser()
    return chain

def find_document(docs, team_code):
    for doc in docs:
        if doc.metadata['Team code'] == team_code:
            return doc
    return None

st.title("í•œë°”ë‹¤ ğŸ¬")
st.header("2024 Ocean ICT ì±—ë´‡ ë„ìš°ë¯¸")

vectorstore = Chroma(
    persist_directory="db/chroma_2024_pdfs",
    embedding_function=OpenAIEmbeddings(openai_api_key=openai_api_key)
)
vectorstore_old = Chroma(
    persist_directory="db/chroma_19to23_pdfs",
    embedding_function=OpenAIEmbeddings(openai_api_key=openai_api_key)
)

retriever = CustomRetriever(vectorstore)
retriever_old = CustomRetriever(vectorstore_old)

qa_chain = setup_rag_pipeline()
googlesheet = GooglesheetUtils()

used_doc_vid = ''

# Chat interface
if "messages" not in st.session_state:
    st.session_state.messages = []

for i in range(len(st.session_state.messages)):
    message = st.session_state.messages[i]
    if message["role"] == "assistant":
        with st.chat_message(name="assistant", avatar='ğŸ‹'):
            st.markdown(message["content"])
    elif message["role"] == "video":
        with st.chat_message(name="assistant", avatar='ğŸ‹'):
            st.video(message["content"])    
    elif message["role"] == "image":
        with st.chat_message(name="assistant", avatar='ğŸ‹'):
            st.image(message["content"], width=360)    
    else:
        with st.chat_message(name="user"):
            st.markdown(message["content"])
        

if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    now_retriever = None
    find_year = YearDistribution("gpt-4o-mini")
    now_year = find_year.Year(prompt).strip()

    now_retriever = retriever.get_ensemble_retriever()
        
    docs = now_retriever.invoke(prompt)
    stream = qa_chain.stream(
        {
            "context": docs,
            "question": prompt
        }
    )

    with st.chat_message(name="assistant", avatar='ğŸ‹'):
        response = st.write_stream(stream)

    used_team_code = [i.strip() for i in response.split('|')[1:]]

    if len(used_team_code) == 1 and 'None' not in used_team_code:
        used_doc = find_document(docs, used_team_code[0])
        used_doc_vid = used_doc.metadata['Youtube link']

        play_video = lambda: st.session_state.messages.append({"role": "video", "content": used_doc_vid})
        show_loc_img = lambda: st.session_state.messages.append({"role": "image", "content": get_location_image(used_team_code)})
        
        col1, col2, col3 = st.columns([1, 1, 3])

        with col1:
            st.button('íŒ€ ì˜ìƒ ë³´ê¸°', on_click=play_video)
        with col2:
            st.button('íŒ€ ìœ„ì¹˜ ë³´ê¸°', on_click=show_loc_img)

    st.session_state.messages.append({"role": "assistant", "content": response})        
    now = datetime.now() + timedelta(hours=9)
    timestamp = now.strftime("%Y-%m-%d %H:%M:%S")

    values = [[prompt, response, timestamp]]
    googlesheet.append_data(values, 'Sheet1!A1')
