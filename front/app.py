import streamlit as st

from db import GooglesheetUtils

from loc_image import get_location_image
from retriever import CustomRetriever
from yeardistribution import YearDistribution

from datetime import datetime, timedelta

__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import sqlite3

from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

from langchain.retrievers.self_query.chroma import ChromaTranslator
from langchain_chroma import Chroma
from langchain.chains.query_constructor.base import AttributeInfo
from langchain.retrievers.self_query.base import SelfQueryRetriever

from langchain.chains.query_constructor.base import (
    StructuredQueryOutputParser,
    get_query_constructor_prompt,
)

openai_api_key = st.secrets['OPENAI_API_KEY']
llm = ChatOpenAI(model_name="gpt-4o", temperature=0, openai_api_key=openai_api_key)

@st.cache_resource
def setup_rag_pipeline():
    prompt = PromptTemplate.from_template(
    """ë‹¹ì‹ ì€ ë¶€ì‚°ê³¼í•™ê³ ë“±í•™êµì˜ í–‰ì‚¬ "Ocean ICT"ì˜ ë„ìš°ë¯¸ ì±—ë´‡ì¸ "í•œë°”ë‹¤" ì…ë‹ˆë‹¤.
    "í•œë°”ë‹¤"ëŠ” ë¶€ì‚°ê³¼í•™ê³  ì •ë³´ R&E í•™ìƒë“¤ì´ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ëŒ€í‘œì ìœ¼ë¡œ ê¹€í™˜, ì„œì¬ì›, ê¹€ì„í˜„ì´ ìˆìŠµë‹ˆë‹¤.
    ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•©ë‹ˆë‹¤.

    ë‹µì„ ëª¨ë¥¸ë‹¤ë©´ ê·¸ëƒ¥ ë‹¹ì‹ ì˜ ì •ë³´ì— ëŒ€í•´ ì–¸ê¸‰í•˜ê³ , Ocean ICTì— ëŒ€í•´ì„œë§Œ ë‹µë³€í•  ìˆ˜ ìˆë‹¤ê³  ë§í•˜ë©´ ë©ë‹ˆë‹¤.
    ë‹µì„ ì•ˆë‹¤ë©´ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì‚¬ìš©í•´ ë‹µë³€í•©ë‹ˆë‹¤. ì¦‰, íŒ€ëª…, íƒêµ¬ ë‚´ìš©, íŒ€ ì½”ë“œ ë“±ì„ í¬í•¨í•´ì„œ ë‹µë³€í•©ë‹ˆë‹¤.
    ë‹µë³€ ë’¤ì—ëŠ” ë‹µì„ ë„ì¶œí•˜ëŠ” ë° ì§ì ‘ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ë¬¸ì„œì˜ íŒ€ ì½”ë“œ ëª©ë¡ì„ ë¬¸ì '|'ë¡œ êµ¬ë¶„í•´ ì•ˆë‚´í•©ë‹ˆë‹¤.
    ì¶œì²˜ê°€ ì—†ëŠ” ê²½ìš° '|' ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í•˜ë‚˜ ì´ìƒì˜ ì¶œì²˜ê°€ ìˆëŠ” ê²½ìš° ë§¨ ë’¤ì— í•œêº¼ë²ˆì— í‘œì‹œí•˜ì„¸ìš”. ë‹µë³€ì˜ ëì—ëŠ” '|'ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    ì¶œì²˜ë¥¼ í‘œì‹œí•˜ê³  ë‚œ í›„ì—ëŠ” ì–´ë– í•œ ê¸€ë„ ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

    ì˜ˆì‹œ ë‹µë³€ 1: 1. B03 íŒ€ê³¼ 2. A11 íŒ€ì´ ìˆìŠµë‹ˆë‹¤. ì´ì™€ ê°™ì´ ë‹¤ì–‘í•œ íŒ€ì´ ì°¸ê°€í•©ë‹ˆë‹¤. | B03 | A11
    ì˜ˆì‹œ ë‹µë³€ 2: C05 íŒ€ì€.. | C05

    #ì§ˆë¬¸:
    {question} ìì„¸í•˜ê²Œ ë‹µë³€í•´ì¤˜.
    #ì •ë³´:
    2024ë…„ì— ì—´ë¦° ì œ 7íšŒ Ocean ICTì—ëŠ” ì´ 96íŒ€ì´ ì°¸ê°€í•˜ì˜€ë‹¤. ë‹¤ìŒì€ ì°¸ê°€í•œ íŒ€ë“¤ì˜ í¬ìŠ¤í„° ì¤‘ ì§ˆë¬¸ê³¼ ê´€ê³„ëœ ì¼ë¶€ì´ë‹¤.
    {context}

    #ë‹µë³€:"""
    )

    chain = prompt | llm | StrOutputParser()
    return chain

def find_document(docs, team_code, now_year):
    for doc in docs:
        if doc.metadata['Team code'] == team_code and \
            doc.metadata['Year'] == now_year:
            return doc
    return None

st.title("í•œë°”ë‹¤ ğŸ¬")
st.header("2024 Ocean ICT ì±—ë´‡ ë„ìš°ë¯¸")

vectorstore = Chroma(
    persist_directory="db/chroma_2024_pdfs",
    embedding_function=OpenAIEmbeddings(openai_api_key=openai_api_key)
)
vectorstore_old = Chroma(
    persist_directory="db/chroma_19to23_pdfs",
    embedding_function=OpenAIEmbeddings(openai_api_key=openai_api_key)
)

retriever = CustomRetriever(vectorstore)
retriever_old = CustomRetriever(vectorstore_old)

qa_chain = setup_rag_pipeline()
googlesheet = GooglesheetUtils()

used_doc_vid = ''

# Chat interface
if "messages" not in st.session_state:
    st.session_state.messages = []

for i in range(len(st.session_state.messages)):
    message = st.session_state.messages[i]
    if message["role"] == "assistant":
        with st.chat_message(name="assistant", avatar='ğŸ‹'):
            st.markdown(message["content"])
    elif message["role"] == "video":
        with st.chat_message(name="assistant", avatar='ğŸ‹'):
            st.video(message["content"])    
    elif message["role"] == "image":
        with st.chat_message(name="assistant", avatar='ğŸ‹'):
            st.image(message["content"], width=360)
    elif message["role"] == "user":
        with st.chat_message(name="user"):
            st.markdown(message["content"])

if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    try:
        now_retriever = None
        find_year = YearDistribution("gpt-4o")
        now_year = find_year.Year(prompt).replace('\n', '').strip()

        print(now_year)

        if now_year != '2024':
            now_retriever = retriever_old.get_ensemble_retriever()
        else:
            now_retriever = retriever.get_ensemble_retriever()
        docs = now_retriever.invoke(prompt)
        stream = qa_chain.stream(
            {
                "context": docs,
                "question": prompt
            }
        )

        with st.chat_message(name="assistant", avatar='ğŸ‹'):
            response = st.write_stream(stream)

        used_team_code = [i.strip() for i in response.split('|')[1:]]
        st.session_state.messages.append({"role": "assistant", "content": response})

        if len(used_team_code) == 1 and 'None' not in used_team_code:
            used_doc = find_document(docs, used_team_code[0], now_year)
            used_doc_vid = used_doc.metadata['Youtube link']
            show_loc_img = lambda: st.session_state.messages.append({"role": "image", "content": get_location_image(used_team_code[0])})

            st.video(used_doc_vid)
            st.session_state.messages.append({"role": "video", "content": used_doc_vid})

            col1, col2 = st.columns([1, 4])
            if now_year == '2024':
                with col1:
                    st.button('íŒ€ ìœ„ì¹˜ ë³´ê¸°', on_click=show_loc_img)
            
        now = datetime.now() + timedelta(hours=9)
        timestamp = now.strftime("%Y-%m-%d %H:%M:%S")

        values = [[prompt, response, timestamp]]
        googlesheet.append_data(values, 'Sheet1!A1')
    except Exception as e:
        with st.chat_message(name="assistant", avatar='ğŸ‹'):
            response = st.markdown('ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”!\n')
            st.markdown(e)
